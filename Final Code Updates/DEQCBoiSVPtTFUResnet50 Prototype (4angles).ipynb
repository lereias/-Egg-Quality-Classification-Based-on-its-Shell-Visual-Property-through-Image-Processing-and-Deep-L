{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "023d1b7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#uncomment below to install gradio library\n",
    "#!pip install gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5dc3e1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46656540",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model training\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing import image as im                   #load image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input      #preprocess image\n",
    "\n",
    "\n",
    "#preprocessing\n",
    "#-------------------------------------------------------------------------\n",
    "# openCV to concatenate\n",
    "import cv2\n",
    "\n",
    "# for image name\n",
    "import random\n",
    "\n",
    "# define and move to dataset directory\n",
    "import os\n",
    "\n",
    "# the directory where the data is stored\n",
    "directory = \"C:/Users/user/Desktop/Dataset\"\n",
    "\n",
    "#for stopping code\n",
    "import sys\n",
    "#-------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5676d6",
   "metadata": {},
   "source": [
    "## Proposed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4709623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    resnet50 = keras.applications.resnet50\n",
    "    \n",
    "    conv_model = resnet50.ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "    for layer in conv_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = keras.layers.GlobalAveragePooling2D()(conv_model.output)\n",
    "    x = keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    predictions = keras.layers.Dense(3, activation='softmax')(x)\n",
    "\n",
    "    full_model = keras.models.Model(inputs=conv_model.input, outputs=predictions)\n",
    "\n",
    "    return full_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7177c34b",
   "metadata": {},
   "source": [
    "## Apply preprocessing to 4 inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ece411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def purepurocessu(img, img2, img3, img4):\n",
    "    \n",
    "    #cropping\n",
    "    #-------------------------------------------------------------------------------------------------------\n",
    "    #crop width and height\n",
    "    width = 3600\n",
    "    height = 3600\n",
    "    \n",
    "    im1 = img\n",
    "        \n",
    "    center = (im1.shape[0] / 2, im1.shape[1] / 2)\n",
    "    #print(center)\n",
    "    x = center[0] - width/2\n",
    "    y = center[1] - height/2\n",
    "        \n",
    "    #slicing to perform cropping\n",
    "    crop_img = im1[int(y):int(y+width), int(x):int(x+height)]\n",
    "    \n",
    "    im2 = img2\n",
    "        \n",
    "    center = (im2.shape[0] / 2, im2.shape[1] / 2)\n",
    "    #print(center)\n",
    "    x = center[0] - width/2\n",
    "    y = center[1] - height/2\n",
    "        \n",
    "    #slicing to perform cropping\n",
    "    crop_img2 = im2[int(y):int(y+width), int(x):int(x+height)]\n",
    "    \n",
    "    im3 = img3\n",
    "        \n",
    "    center = (im3.shape[0] / 2, im3.shape[1] / 2)\n",
    "    #print(center)\n",
    "    x = center[0] - width/2\n",
    "    y = center[1] - height/2\n",
    "        \n",
    "    #slicing to perform cropping\n",
    "    crop_img3 = im3[int(y):int(y+width), int(x):int(x+height)]\n",
    "    \n",
    "    im4 = img4\n",
    "        \n",
    "    center = (im4.shape[0] / 2, im4.shape[1] / 2)\n",
    "    #print(center)\n",
    "    x = center[0] - width/2\n",
    "    y = center[1] - height/2\n",
    "        \n",
    "    #slicing to perform cropping\n",
    "    crop_img4 = im4[int(y):int(y+width), int(x):int(x+height)]\n",
    "    #-------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #concatenate and resize\n",
    "    #-------------------------------------------------------------------------------------------------------\n",
    "    #resize for ResNet50\n",
    "    width = 224\n",
    "    height = 224\n",
    "\n",
    "    dim = (width,height)\n",
    "            \n",
    "    im_v = cv2.vconcat([cv2.resize(im1, dim), cv2.resize(im2, dim)])\n",
    "    im_v2 = cv2.vconcat([cv2.resize(im3, dim), cv2.resize(im4, dim)])\n",
    "    im_v3 = cv2.hconcat([im_v, im_v2])\n",
    "    \n",
    "    im_v3 = cv2.resize(im_v3, dim)\n",
    "    \n",
    "    #-------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    return im_v3   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f15fb2",
   "metadata": {},
   "source": [
    "## UI using Gradio Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8132027",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally at: http://127.0.0.1:7860/\n",
      "To create a public link, set `share=True` in `launch()`.\n",
      "Interface loading below...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7860/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x147051a5280>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Flask 'gradio.networking'>, 'http://127.0.0.1:7860/', None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "\n",
    "labels = ['Balut/Penoy','Salted egg','Table egg']\n",
    "\n",
    "def duckeggpred(angle_1,angle_2,angle_3,angle_4):\n",
    "    \n",
    "    full_model = None\n",
    "    predictionu = None\n",
    "    \n",
    "    img = purepurocessu(angle_1,angle_2,angle_3,angle_4)\n",
    "    \n",
    "    img = img.reshape((-1, 224, 224, 3))   \n",
    "    \n",
    "    full_model = create_model()\n",
    "    \n",
    "    save_dir = \"C:/Users/user/Desktop/Model/saved_finalmodel_1\"\n",
    "    \n",
    "    # Load the best model instance to evaluate the performance of the model\n",
    "    full_model.load_weights(save_dir+\"/\"+ \"finalmodel_1.h5\")\n",
    "    \n",
    "    predictionu = full_model.predict(img, verbose=0).flatten() \n",
    "    #print(predictionu)\n",
    "    \n",
    "    return {labels[i]: float(predictionu[i]) for i in range(len(labels))}\n",
    "\n",
    "iface = gr.Interface(duckeggpred, \n",
    "                     [gr.inputs.Image(),gr.inputs.Image(),gr.inputs.Image(),gr.inputs.Image()], \n",
    "                     gr.outputs.Label(num_top_classes = 3),\n",
    "                     title=\"\"\"\n",
    "                           Duck Egg Classification Based on its Shell Visual Property through Transfer Learning Using \n",
    "                           ResNet50\n",
    "                           \"\"\",\n",
    "                     description=\"\"\"\n",
    "                                 This is a prototype that will predict the duck egg images (2 angles) to 3 classes \n",
    "                                 (Balut/Penoy, Salted egg, Table egg). It will use the weights of the results of \n",
    "                                 training our model using our dataset in order to do the prediction.\n",
    "                                 \"\"\"\n",
    "                     ,)\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56f6956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
